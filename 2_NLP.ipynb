{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hired-cutting",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-reflection",
   "metadata": {},
   "source": [
    "### Import NLP Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "portuguese-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accompanied-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/winemag-data-130k-v2.csv')\n",
    "df = df[['description', 'title', 'variety']]\n",
    "df = df.dropna()\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-intention",
   "metadata": {},
   "source": [
    "Download NLTK Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "boring-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptionList = list()\n",
    "lemma = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-protein",
   "metadata": {},
   "source": [
    "Big wait time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-saturday",
   "metadata": {},
   "source": [
    "### Applying NLP only on description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "for description in tqdm(df.description):\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description) # We use regular expression to delete non-alphabetic characters on data.\n",
    "    description = description.lower() # Since upper and lower characters are (e.g a - A) evaluated like they are different each other by computer we make turn whole characters into lowercase.\n",
    "    description = nltk.word_tokenize(description) # We tokenized the statement\n",
    "    description = [i for i in description if not i in set(stopwords.words(\"english\"))] # We will remove words like 'the', 'or', 'and', 'is' etc.\n",
    "    description = [lemma.lemmatize(i)for i in description] # e.g: loved => love\n",
    "    description = \" \".join(description) # Now we turn our words list into sentence again\n",
    "    descriptionList.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "descDF = pd.DataFrame(descriptionList)\n",
    "descDF.to_csv('data/description_list_description_only_NA_dropped.csv')\n",
    "descDF.to_pickle('data/description_list_description_only_NA_dropped.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-doctor",
   "metadata": {},
   "source": [
    "### Applying NLP on merging title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "controversial-printing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe9cbf5d92c4595b43e45d94dec1239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "descriptionList = list()\n",
    "lemma = nltk.WordNetLemmatizer()\n",
    "for i in tqdm(range(len(df))):\n",
    "    description = df.title[i] + \". \" + df.description[i]\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description) # We use regular expression to delete non-alphabetic characters on data.\n",
    "    description = description.lower() # Since upper and lower characters are (e.g a - A) evaluated like they are different each other by computer we make turn whole characters into lowercase.\n",
    "    description = nltk.word_tokenize(description) # We tokenized the statement\n",
    "    description = [i for i in description if not i in set(stopwords.words(\"english\"))] # We will remove words like 'the', 'or', 'and', 'is' etc.\n",
    "    description = [lemma.lemmatize(i)for i in description] # e.g: loved => love\n",
    "    description = \" \".join(description) # Now we turn our words list into sentence again\n",
    "    descriptionList.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advanced-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "descDF = pd.DataFrame(descriptionList)\n",
    "descDF.to_csv('data/description_list_title_desc_NA_dropped.csv')\n",
    "descDF.to_pickle('data/description_list_title_desc_NA_dropped.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-thesis",
   "metadata": {},
   "source": [
    "#### Understanding Each Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "difficult-major",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1>  Nicosia 2013 VulkÃ  Bianco  (Etna). Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\n",
      "2>  Nicosia      Vulk  Bianco   Etna   Aromas include tropical fruit  broom  brimstone and dried herb  The palate isn t overly expressive  offering unripened apple  citrus and dried sage alongside brisk acidity \n",
      "3>  nicosia      vulk  bianco   etna   aromas include tropical fruit  broom  brimstone and dried herb  the palate isn t overly expressive  offering unripened apple  citrus and dried sage alongside brisk acidity \n",
      "4>  ['nicosia', 'vulk', 'bianco', 'etna', 'aromas', 'include', 'tropical', 'fruit', 'broom', 'brimstone', 'and', 'dried', 'herb', 'the', 'palate', 'isn', 't', 'overly', 'expressive', 'offering', 'unripened', 'apple', 'citrus', 'and', 'dried', 'sage', 'alongside', 'brisk', 'acidity']\n",
      "5>  ['nicosia', 'vulk', 'bianco', 'etna', 'aromas', 'include', 'tropical', 'fruit', 'broom', 'brimstone', 'dried', 'herb', 'palate', 'overly', 'expressive', 'offering', 'unripened', 'apple', 'citrus', 'dried', 'sage', 'alongside', 'brisk', 'acidity']\n",
      "6>  ['nicosia', 'vulk', 'bianco', 'etna', 'aroma', 'include', 'tropical', 'fruit', 'broom', 'brimstone', 'dried', 'herb', 'palate', 'overly', 'expressive', 'offering', 'unripened', 'apple', 'citrus', 'dried', 'sage', 'alongside', 'brisk', 'acidity']\n",
      "7>  nicosia vulk bianco etna aroma include tropical fruit broom brimstone dried herb palate overly expressive offering unripened apple citrus dried sage alongside brisk acidity\n"
     ]
    }
   ],
   "source": [
    "description = df.title[0] + \". \" + df.description[0]\n",
    "print('1> ', description)\n",
    "description = re.sub(\"[^a-zA-Z]\",\" \",description) # We use regular expression to delete non-alphabetic characters on data.\n",
    "print('2> ', description)\n",
    "description = description.lower() # Since upper and lower characters are (e.g a - A) evaluated like they are different each other by computer we make turn whole characters into lowercase.\n",
    "print('3> ', description)\n",
    "description = nltk.word_tokenize(description) # We tokenized the statement\n",
    "print('4> ', description)\n",
    "description = [i for i in description if not i in set(stopwords.words(\"english\"))] # We will remove words like 'the', 'or', 'and', 'is' etc.\n",
    "print('5> ', description)\n",
    "description = [lemma.lemmatize(i)for i in description] # e.g: loved => love\n",
    "print('6> ', description)\n",
    "description = \" \".join(description) # Now we turn our words list into sentence again\n",
    "print('7> ', description)\n",
    "descriptionList.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-boxing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
