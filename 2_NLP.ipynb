{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hired-cutting",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-reflection",
   "metadata": {},
   "source": [
    "### Import NLP Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "portuguese-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk as nlp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accompanied-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/winemag-data-130k-v2.csv')\n",
    "df = df[['description', 'variety']]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-intention",
   "metadata": {},
   "source": [
    "Download NLTK Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "arabic-naples",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "boring-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptionList = list()\n",
    "lemma = nlp.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-protein",
   "metadata": {},
   "source": [
    "Big wait time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "polish-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "another-hayes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19da3e5d7824d9b85565102f3652680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for description in tqdm(df.description):\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description) # We use regular expression to delete non-alphabetic characters on data.\n",
    "    description = description.lower() # Since upper and lower characters are (e.g a - A) evaluated like they are different each other by computer we make turn whole characters into lowercase.\n",
    "    description = nltk.word_tokenize(description) # We tokenized the statement\n",
    "    description = [i for i in description if not i in set(stopwords.words(\"english\"))] # We will remove words like 'the', 'or', 'and', 'is' etc.\n",
    "    description = [lemma.lemmatize(i)for i in description] # e.g: loved => love\n",
    "    description = \" \".join(description) # Now we turn our words list into sentence again\n",
    "    descriptionList.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "broken-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "descDF = pd.DataFrame(descriptionList)\n",
    "descDF.to_csv('data/description_list_description_only_NA_dropped.csv')\n",
    "descDF.to_pickle('data/description_list_description_only_NA_dropped.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
